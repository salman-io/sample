<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>SmileTracker â€” Web</title>
  <meta name="description" content="SmileTracker â€” detects emotions from your webcam and replaces faces with suitable emojis." />
  <style>
    body{font-family:Arial,sans-serif;background:#111;color:#fff;display:flex;align-items:center;justify-content:center;height:100vh;margin:0;flex-direction:column}
    canvas{border:2px solid #444;border-radius:8px;max-width:90%;height:auto;background:black}
    button{margin:5px;padding:10px 20px;border:none;border-radius:5px;cursor:pointer}
    #status{margin-top:10px;font-size:14px;color:#aaa}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.min.js"></script>
</head>
<body>
  <h1>SmileTracker â€” Emoji by Emotion</h1>
  <canvas id="canvas"></canvas>
  <div>
    <button id="startBtn">Start Camera</button>
    <button id="stopBtn">Stop Camera</button>
  </div>
  <div id="status">Status: idle</div>

  <script>
    const canvas = document.getElementById('canvas');
    const statusEl = document.getElementById('status');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    let video;
    let stream = null;
    let detectionInterval;

    const emotionEmojis = {
      happy: 'ðŸ˜Š',
      sad: 'ðŸ˜¢',
      angry: 'ðŸ˜ ',
      surprised: 'ðŸ˜®',
      fearful: 'ðŸ˜¨',
      disgusted: 'ðŸ¤¢',
      neutral: 'ðŸ˜'
    };

    async function loadModels() {
      statusEl.textContent = 'Loading modelsâ€¦';
      const modelURL = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/';
      await faceapi.nets.tinyFaceDetector.loadFromUri(modelURL);
      await faceapi.nets.faceExpressionNet.loadFromUri(modelURL);
      statusEl.textContent = 'Models loaded';
    }

    async function startCamera(){
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        statusEl.textContent = 'Camera not supported in this browser';
        return;
      }
      try {
        video = document.createElement('video');
        stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
        video.srcObject = stream;
        await video.play();
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        statusEl.textContent = 'Camera running';
        startDetection();
      } catch (err) {
        console.error('getUserMedia error:', err);
        statusEl.textContent = `Camera error: ${err.name} â€” ${err.message}`;
      }
    }

    function stopCamera(){
      if (stream){
        stream.getTracks().forEach(t=>t.stop());
        stream = null;
        statusEl.textContent = 'Camera stopped';
        clearInterval(detectionInterval);
      }
    }

    async function startDetection() {
      const ctx = canvas.getContext('2d');
      detectionInterval = setInterval(async () => {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
        detections.forEach(det => {
          const { x, y, width, height } = det.detection.box;
          const expressions = det.expressions;
          const mainExpression = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
          const emoji = emotionEmojis[mainExpression] || 'ðŸ™‚';

          ctx.clearRect(x, y, width, height);
          ctx.font = `${Math.floor(height)}px sans-serif`;
          ctx.fillText(emoji, x, y + height - 10);
        });
      }, 150);
    }

    window.addEventListener('load', async () => {
      await loadModels();
      startCamera();
    });
    startBtn.addEventListener('click', startCamera);
    stopBtn.addEventListener('click', stopCamera);
  </script>

  <!-- GitHub Pages note -->
  <!-- Push this HTML file to a public GitHub repo, enable Pages in repo settings, set branch to main (or master) and folder to /root. Access it via https://yourusername.github.io/reponame. GitHub Pages uses HTTPS, so getUserMedia will work if camera permissions are granted. -->
</body>
</html>
